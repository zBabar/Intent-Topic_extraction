{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dataset Shape: (10, 15)\n",
      "Target Dataset Shape: (10, 15)\n",
      "Input Dataset: [[15 30 32  1 16 17  6 10 29 30 17 21 49 43 18]\n",
      " [ 3 49 25 49 32 32 22  8 32 18 24 23  7 20 38]\n",
      " [41 16 15 18 23 23 34 24 19 24 33 17 30 25 43]\n",
      " [39  9 18  1 28 33 28 43 37 15 31 48 22 21 16]\n",
      " [10 25 27 24 44 34 11 11  9 28 21 40 41 34  7]\n",
      " [16 13 20  1 41 18  6  3 24 18 23 49  6 31  1]\n",
      " [34 34 37 49 40  7 20 42 43 22  3 28 37  6 43]\n",
      " [25 37 45  1 34  4 38 29 22 34 47 44 20 27 31]\n",
      " [12 33 14  6 36 37 46  9  6 29 49 19 32 35 19]\n",
      " [ 3 11 21  5 14 15 16 11  0 12 45 14 30 26 39]]\n",
      "Target Dataset: [[30 32  1 16 17  6 10 29 30 17 21 49 43 18  0]\n",
      " [49 25 49 32 32 22  8 32 18 24 23  7 20 38  0]\n",
      " [16 15 18 23 23 34 24 19 24 33 17 30 25 43  0]\n",
      " [ 9 18  1 28 33 28 43 37 15 31 48 22 21 16  0]\n",
      " [25 27 24 44 34 11 11  9 28 21 40 41 34  7  0]\n",
      " [13 20  1 41 18  6  3 24 18 23 49  6 31  1  0]\n",
      " [34 37 49 40  7 20 42 43 22  3 28 37  6 43  0]\n",
      " [37 45  1 34  4 38 29 22 34 47 44 20 27 31  0]\n",
      " [33 14  6 36 37 46  9  6 29 49 19 32 35 19  0]\n",
      " [11 21  5 14 15 16 11  0 12 45 14 30 26 39  0]]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zaheerbabar/miniforge3/envs/NLP/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9123  \n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9051 \n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9017 \n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8960 \n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8911 \n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8838 \n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8756 \n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8657 \n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8497 \n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8345 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 3.8156\n",
      "Loss: 3.8155598640441895\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of sequences, their length, and the vocabulary size\n",
    "num_sequences = 10\n",
    "sequence_length = 15\n",
    "vocab_size = 50\n",
    "\n",
    "# Generate random integer data to simulate sequences of words\n",
    "dataset = np.random.randint(0, vocab_size, size=(num_sequences, sequence_length))\n",
    "\n",
    "# Create target sequences by shifting each sequence by one index to the right\n",
    "target_dataset = np.concatenate([dataset[:, 1:], np.zeros((num_sequences, 1), dtype=int)], axis=1)\n",
    "\n",
    "print(\"Input Dataset Shape:\", dataset.shape)  # Output shape: (10, 15)\n",
    "print(\"Target Dataset Shape:\", target_dataset.shape)  # Output shape: (10, 15)\n",
    "\n",
    "print(\"Input Dataset:\", dataset)\n",
    "print(\"Target Dataset:\", target_dataset)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=16, input_length=sequence_length),\n",
    "    tf.keras.layers.GRU(units=32, return_sequences=True),\n",
    "    tf.keras.layers.Dense(units=vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset, target_dataset, epochs=10, batch_size=2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(dataset, target_dataset)\n",
    "print(f\"Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "New Sequence: [[21 49 44 42 14 10 30  5  5 15 40 48 26 48 37]]\n",
      "Predicted Next Word: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the next word for a new sequence\n",
    "new_sequence = np.random.randint(0, vocab_size, size=(1, sequence_length))\n",
    "predicted_probs = model.predict(new_sequence)\n",
    "predicted_word = np.argmax(predicted_probs, axis=-1)\n",
    "\n",
    "print(\"New Sequence:\", new_sequence)\n",
    "print(\"Predicted Next Word:\", predicted_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
